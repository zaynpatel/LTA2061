{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d3e8459",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "import string\n",
    "import numpy as np\n",
    "import sympy as sp\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7c95a4",
   "metadata": {},
   "source": [
    "### Build the columns of our future document term matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82688492",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['who',\n",
       " 'has',\n",
       " 'not',\n",
       " 'waked',\n",
       " 'to',\n",
       " 'list',\n",
       " 'the',\n",
       " 'busy',\n",
       " 'sounds',\n",
       " 'of',\n",
       " 'summer’s',\n",
       " 'morning',\n",
       " 'in',\n",
       " 'the',\n",
       " 'sultry',\n",
       " 'smoke',\n",
       " 'of',\n",
       " 'noisy',\n",
       " 'london',\n",
       " 'on',\n",
       " 'the',\n",
       " 'pavement',\n",
       " 'hot',\n",
       " 'the',\n",
       " 'sooty',\n",
       " 'chimneyboy',\n",
       " 'with',\n",
       " 'dingy',\n",
       " 'face',\n",
       " 'and',\n",
       " 'tattered',\n",
       " 'covering',\n",
       " 'shrilly',\n",
       " 'bawls',\n",
       " 'his',\n",
       " 'trade',\n",
       " 'rousing',\n",
       " 'the',\n",
       " 'sleepy',\n",
       " 'housemaid',\n",
       " 'at',\n",
       " 'the',\n",
       " 'door',\n",
       " 'the',\n",
       " 'milkpail',\n",
       " 'rattles',\n",
       " 'and',\n",
       " 'the',\n",
       " 'tinkling',\n",
       " 'bell',\n",
       " 'proclaims',\n",
       " 'the',\n",
       " 'dustman’s',\n",
       " 'office',\n",
       " 'while',\n",
       " 'the',\n",
       " 'street',\n",
       " 'is',\n",
       " 'lost',\n",
       " 'in',\n",
       " 'clouds',\n",
       " 'impervious',\n",
       " 'now',\n",
       " 'begins',\n",
       " 'the',\n",
       " 'din',\n",
       " 'of',\n",
       " 'hackneycoaches',\n",
       " 'waggons',\n",
       " 'carts',\n",
       " 'while',\n",
       " 'tinmen’s',\n",
       " 'shops',\n",
       " 'and',\n",
       " 'noisy',\n",
       " 'trunkmakers',\n",
       " 'knifegrinders',\n",
       " 'coopers',\n",
       " 'squeaking',\n",
       " 'corkcutters',\n",
       " 'fruitbarrows',\n",
       " 'and',\n",
       " 'the',\n",
       " 'hungergiving',\n",
       " 'cries',\n",
       " 'of',\n",
       " 'vegetablevendors',\n",
       " 'fill',\n",
       " 'the',\n",
       " 'air',\n",
       " 'now',\n",
       " 'every',\n",
       " 'shop',\n",
       " 'displays',\n",
       " 'its',\n",
       " 'varied',\n",
       " 'trade',\n",
       " 'and',\n",
       " 'the',\n",
       " 'freshsprinkled',\n",
       " 'pavement',\n",
       " 'cools',\n",
       " 'the',\n",
       " 'feet',\n",
       " 'of',\n",
       " 'early',\n",
       " 'walkers',\n",
       " 'at',\n",
       " 'the',\n",
       " 'private',\n",
       " 'door',\n",
       " 'the',\n",
       " 'ruddy',\n",
       " 'housemaid',\n",
       " 'twirls',\n",
       " 'the',\n",
       " 'busy',\n",
       " 'mop',\n",
       " 'annoying',\n",
       " 'the',\n",
       " 'smart',\n",
       " '’prentice',\n",
       " 'or',\n",
       " 'neat',\n",
       " 'girl',\n",
       " 'tripping',\n",
       " 'with',\n",
       " 'bandbox',\n",
       " 'lightly',\n",
       " 'now',\n",
       " 'the',\n",
       " 'sun',\n",
       " 'darts',\n",
       " 'burning',\n",
       " 'splendor',\n",
       " 'on',\n",
       " 'the',\n",
       " 'glittering',\n",
       " 'pane',\n",
       " 'save',\n",
       " 'where',\n",
       " 'the',\n",
       " 'canvas',\n",
       " 'awning',\n",
       " 'throws',\n",
       " 'a',\n",
       " 'shade',\n",
       " 'on',\n",
       " 'the',\n",
       " 'gay',\n",
       " 'merchandise',\n",
       " 'now',\n",
       " 'spruce',\n",
       " 'and',\n",
       " 'trim',\n",
       " 'in',\n",
       " 'shops',\n",
       " 'where',\n",
       " 'beauty',\n",
       " 'smiles',\n",
       " 'with',\n",
       " 'industry',\n",
       " 'sits',\n",
       " 'the',\n",
       " 'smart',\n",
       " 'damsel',\n",
       " 'while',\n",
       " 'the',\n",
       " 'passenger',\n",
       " 'peeps',\n",
       " 'through',\n",
       " 'the',\n",
       " 'window',\n",
       " 'watching',\n",
       " 'every',\n",
       " 'charm',\n",
       " 'now',\n",
       " 'pastry',\n",
       " 'dainties',\n",
       " 'catch',\n",
       " 'the',\n",
       " 'eye',\n",
       " 'minute',\n",
       " 'of',\n",
       " 'humming',\n",
       " 'insects',\n",
       " 'while',\n",
       " 'the',\n",
       " 'limy',\n",
       " 'snare',\n",
       " 'waits',\n",
       " 'to',\n",
       " 'enthrall',\n",
       " 'them',\n",
       " 'now',\n",
       " 'the',\n",
       " 'lamplighter',\n",
       " 'mounts',\n",
       " 'the',\n",
       " 'tall',\n",
       " 'ladder',\n",
       " 'nimbly',\n",
       " 'venturous',\n",
       " 'to',\n",
       " 'trim',\n",
       " 'the',\n",
       " 'halffilled',\n",
       " 'lamps',\n",
       " 'while',\n",
       " 'at',\n",
       " 'his',\n",
       " 'feet',\n",
       " 'the',\n",
       " 'potboy',\n",
       " 'yells',\n",
       " 'discordant',\n",
       " 'all',\n",
       " 'along',\n",
       " 'the',\n",
       " 'sultry',\n",
       " 'pavement',\n",
       " 'the',\n",
       " 'oldclothesman',\n",
       " 'cries',\n",
       " 'in',\n",
       " 'tone',\n",
       " 'monotonous',\n",
       " 'while',\n",
       " 'sidelong',\n",
       " 'views',\n",
       " 'the',\n",
       " 'area',\n",
       " 'for',\n",
       " 'his',\n",
       " 'traffic',\n",
       " 'now',\n",
       " 'the',\n",
       " 'bag',\n",
       " 'is',\n",
       " 'slyly',\n",
       " 'opened',\n",
       " 'and',\n",
       " 'the',\n",
       " 'halfworn',\n",
       " 'suit',\n",
       " 'sometimes',\n",
       " 'the',\n",
       " 'pilfered',\n",
       " 'treasure',\n",
       " 'of',\n",
       " 'the',\n",
       " 'base',\n",
       " 'domestic',\n",
       " 'spoiler',\n",
       " 'for',\n",
       " 'one',\n",
       " 'half',\n",
       " 'its',\n",
       " 'worth',\n",
       " 'sinks',\n",
       " 'in',\n",
       " 'the',\n",
       " 'green',\n",
       " 'abyss',\n",
       " 'the',\n",
       " 'porter',\n",
       " 'now',\n",
       " 'bears',\n",
       " 'his',\n",
       " 'huge',\n",
       " 'load',\n",
       " 'along',\n",
       " 'the',\n",
       " 'burning',\n",
       " 'way',\n",
       " 'and',\n",
       " 'the',\n",
       " 'poor',\n",
       " 'poet',\n",
       " 'wakes',\n",
       " 'from',\n",
       " 'busy',\n",
       " 'dreams',\n",
       " 'to',\n",
       " 'paint',\n",
       " 'the',\n",
       " 'summer',\n",
       " 'morning']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scrape first link\n",
    "response = requests.get(\"https://www.poetryfoundation.org/poems/51900/londons-summer-morning\")\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "divs = soup.find_all('div', class_ = \"poem-body overflow-x-auto\")\n",
    "\n",
    "# Clean divs\n",
    "for div in divs:\n",
    "    poem_text = div.text.lower()\n",
    "    poem_text_no_punc = poem_text.translate(str.maketrans('', '', string.punctuation))\n",
    "    poem = (poem_text_no_punc.split()) # Lower text and include no punctuation when we append\n",
    "\n",
    "poem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ce0fcb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove stopwords\n",
    "stopword_list = ['the', 'and', 'is', 'in', 'to', 'of']\n",
    "poem_no_stopword = [word for word in poem if word not in stopword_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db82b65",
   "metadata": {},
   "source": [
    "### Build the rows of our future document term matrix\n",
    "\n",
    "In this exercise I am going to define document by sentences of the poem which are split based on punctuation. Our first step in building the document term matrix is to define and pull our documents. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a408fe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['who has not waked to list the busy sounds of summer’s morning, in the sultry smoke of noisy london',\n",
       " ' on the pavement hot the sooty chimney-boy, with dingy face and tattered covering, shrilly bawls his trade, rousing the sleepy housemaid',\n",
       " ' at the door the milk-pail rattles, and the tinkling bell proclaims the dustman’s office; while the street is lost in clouds impervious',\n",
       " ' now begins the din of hackney-coaches, waggons, carts; while tinmen’s shops, and noisy trunk-makers, knife-grinders, coopers, squeaking cork-cutters, fruit-barrows, and the hunger-giving cries of vegetable-vendors, fill the air',\n",
       " ' now every shop displays its varied trade, and the fresh-sprinkled pavement cools the feet of early walkers',\n",
       " ' at the private door the ruddy housemaid twirls the busy mop, annoying the smart ’prentice, or neat girl, tripping with band-box lightly',\n",
       " ' now the sun darts burning splendor on the glittering pane, save where the canvas awning throws a shade on the gay merchandise',\n",
       " ' now, spruce and trim, in shops ',\n",
       " 'where beauty smiles with industry',\n",
       " ' sits the smart damsel; while the passenger peeps through the window, watching every charm',\n",
       " ' now pastry dainties catch the eye minute of humming insects, while the limy snare waits to enthrall them',\n",
       " ' now the lamp-lighter mounts the tall ladder, nimbly venturous, to trim the half-filled lamps, while at his feet the pot-boy yells discordant',\n",
       " ' all along the sultry pavement, the old-clothes-man cries in tone monotonous, while sidelong views the area for his traffic: now the bag is slyly opened, and the half-worn suit ',\n",
       " 'sometimes the pilfered treasure of the base domestic spoiler',\n",
       " ', for one half its worth, sinks in the green abyss',\n",
       " ' the porter now bears his huge load along the burning way; and the poor poet wakes from busy dreams, to paint the summer morning',\n",
       " '']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = requests.get(\"https://www.poetryfoundation.org/poems/51900/londons-summer-morning\")\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "divs = soup.find_all('div', class_ = \"poem-body overflow-x-auto\")\n",
    "\n",
    "# Clean divs\n",
    "for div in divs:\n",
    "    poem_text = div.text.lower()\n",
    "    # Later note: Needed to remove parentheses since this messed up the sorted structure a few blocks down\n",
    "    poem_text = re.split(r'[.!?()]', poem_text) # Use regex split so we can split by multiple punctuation types\n",
    "\n",
    "poem_text # Now we have multiple topics \"documents split by punctuation\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20261a40",
   "metadata": {},
   "source": [
    "The next step is to build a vocabulary of unique words. We want to do this because we will use the unique words that appear in the dataset to construct our column index in the document-term matrix.\n",
    "\n",
    "To do this we will use a \"global vocabulary\" and make a set of the unqiue words from the entire document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b16f7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_poem_set = set()\n",
    "\n",
    "for sentence in poem_text:\n",
    "    words = sentence.split() # Split the 13 sentences into words\n",
    "    for word in words:\n",
    "        unique_poem_set.update(words) # Create a set of words that and .update() the set for each iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2e144d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[',',\n",
       " 'a',\n",
       " 'abyss',\n",
       " 'air',\n",
       " 'all',\n",
       " 'along',\n",
       " 'and',\n",
       " 'annoying',\n",
       " 'area',\n",
       " 'at',\n",
       " 'awning',\n",
       " 'bag',\n",
       " 'band-box',\n",
       " 'base',\n",
       " 'bawls',\n",
       " 'bears',\n",
       " 'beauty',\n",
       " 'begins',\n",
       " 'bell',\n",
       " 'burning',\n",
       " 'busy',\n",
       " 'canvas',\n",
       " 'carts;',\n",
       " 'catch',\n",
       " 'charm',\n",
       " 'chimney-boy,',\n",
       " 'clouds',\n",
       " 'cools',\n",
       " 'coopers,',\n",
       " 'cork-cutters,',\n",
       " 'covering,',\n",
       " 'cries',\n",
       " 'dainties',\n",
       " 'damsel;',\n",
       " 'darts',\n",
       " 'din',\n",
       " 'dingy',\n",
       " 'discordant',\n",
       " 'displays',\n",
       " 'domestic',\n",
       " 'door',\n",
       " 'dreams,',\n",
       " 'dustman’s',\n",
       " 'early',\n",
       " 'enthrall',\n",
       " 'every',\n",
       " 'eye',\n",
       " 'face',\n",
       " 'feet',\n",
       " 'fill',\n",
       " 'for',\n",
       " 'fresh-sprinkled',\n",
       " 'from',\n",
       " 'fruit-barrows,',\n",
       " 'gay',\n",
       " 'girl,',\n",
       " 'glittering',\n",
       " 'green',\n",
       " 'hackney-coaches,',\n",
       " 'half',\n",
       " 'half-filled',\n",
       " 'half-worn',\n",
       " 'has',\n",
       " 'his',\n",
       " 'hot',\n",
       " 'housemaid',\n",
       " 'huge',\n",
       " 'humming',\n",
       " 'hunger-giving',\n",
       " 'impervious',\n",
       " 'in',\n",
       " 'industry',\n",
       " 'insects,',\n",
       " 'is',\n",
       " 'its',\n",
       " 'knife-grinders,',\n",
       " 'ladder,',\n",
       " 'lamp-lighter',\n",
       " 'lamps,',\n",
       " 'lightly',\n",
       " 'limy',\n",
       " 'list',\n",
       " 'load',\n",
       " 'london',\n",
       " 'lost',\n",
       " 'merchandise',\n",
       " 'milk-pail',\n",
       " 'minute',\n",
       " 'monotonous,',\n",
       " 'mop,',\n",
       " 'morning',\n",
       " 'morning,',\n",
       " 'mounts',\n",
       " 'neat',\n",
       " 'nimbly',\n",
       " 'noisy',\n",
       " 'not',\n",
       " 'now',\n",
       " 'now,',\n",
       " 'of',\n",
       " 'office;',\n",
       " 'old-clothes-man',\n",
       " 'on',\n",
       " 'one',\n",
       " 'opened,',\n",
       " 'or',\n",
       " 'paint',\n",
       " 'pane,',\n",
       " 'passenger',\n",
       " 'pastry',\n",
       " 'pavement',\n",
       " 'pavement,',\n",
       " 'peeps',\n",
       " 'pilfered',\n",
       " 'poet',\n",
       " 'poor',\n",
       " 'porter',\n",
       " 'pot-boy',\n",
       " 'private',\n",
       " 'proclaims',\n",
       " 'rattles,',\n",
       " 'rousing',\n",
       " 'ruddy',\n",
       " 'save',\n",
       " 'shade',\n",
       " 'shop',\n",
       " 'shops',\n",
       " 'shops,',\n",
       " 'shrilly',\n",
       " 'sidelong',\n",
       " 'sinks',\n",
       " 'sits',\n",
       " 'sleepy',\n",
       " 'slyly',\n",
       " 'smart',\n",
       " 'smiles',\n",
       " 'smoke',\n",
       " 'snare',\n",
       " 'sometimes',\n",
       " 'sooty',\n",
       " 'sounds',\n",
       " 'splendor',\n",
       " 'spoiler',\n",
       " 'spruce',\n",
       " 'squeaking',\n",
       " 'street',\n",
       " 'suit',\n",
       " 'sultry',\n",
       " 'summer',\n",
       " 'summer’s',\n",
       " 'sun',\n",
       " 'tall',\n",
       " 'tattered',\n",
       " 'the',\n",
       " 'them',\n",
       " 'through',\n",
       " 'throws',\n",
       " 'tinkling',\n",
       " 'tinmen’s',\n",
       " 'to',\n",
       " 'tone',\n",
       " 'trade,',\n",
       " 'traffic:',\n",
       " 'treasure',\n",
       " 'trim',\n",
       " 'trim,',\n",
       " 'tripping',\n",
       " 'trunk-makers,',\n",
       " 'twirls',\n",
       " 'varied',\n",
       " 'vegetable-vendors,',\n",
       " 'venturous,',\n",
       " 'views',\n",
       " 'waggons,',\n",
       " 'waits',\n",
       " 'waked',\n",
       " 'wakes',\n",
       " 'walkers',\n",
       " 'watching',\n",
       " 'way;',\n",
       " 'where',\n",
       " 'while',\n",
       " 'who',\n",
       " 'window,',\n",
       " 'with',\n",
       " 'worth,',\n",
       " 'yells',\n",
       " '’prentice,']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_poem_sorted = sorted(unique_poem_set)\n",
    "unique_poem_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3557e343",
   "metadata": {},
   "source": [
    "### Build the document-term matrix\n",
    "\n",
    "Observation: The document-term matrix should have dimensions number of documents x number of words so I will take len() of these before I initialize the zero matrix and begin updating entries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65cc0dba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check lengths\n",
    "\n",
    "len(unique_poem_sorted) # 188 words\n",
    "len(poem_text) # 17 documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57b68d43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [1., 0., 1., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize a 17 x 187 zero matrix\n",
    "dtm = np.zeros((17, 188))\n",
    "\n",
    "\n",
    "# Make a lookup dictionary for the words (O(1) lookup in best case)\n",
    "# We know this lookup only contains words in our unique_poem_sorted\n",
    "word_lookup = { v : k for k, v in enumerate(unique_poem_sorted)}\n",
    "\n",
    "for d_idx, document in enumerate(poem_text):\n",
    "    for word in document.split():\n",
    "        word_idx = word_lookup[word]\n",
    "        dtm[d_idx][word_idx] += 1\n",
    "dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64cde6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert unique_poem_sorted[182] == 'who'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "17217e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that the word 'who' has a 1 in the document 0, entry 182\n",
    "assert dtm[0][182] == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae6e4397",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.09090909, 0.        , 0.09090909, ..., 0.09090909, 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use TF formula (from Wikipedia) to normalize word frequencies\n",
    "# This sums row-wise\n",
    "row_sums = np.sum(dtm, axis = 1, keepdims=True)\n",
    "\n",
    "# This np.divide method ensures we skip over rows with zeros and prevent division by zero errors\n",
    "#tf_matrix = np.divide(dtm, row_sums, where = row_sums != 0)\n",
    "# Add the tiny constant 1e-10 to avoid Runtime Warnings about division with zero\n",
    "\n",
    "tf_matrix = np.where(row_sums != 0, np.divide(dtm, row_sums + 1e-10), 0)\n",
    "tf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "57d33b56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.14006616, 3.14006616, 3.14006616, 3.14006616, 3.14006616,\n",
       "       2.73460106, 1.63598877, 3.14006616, 3.14006616, 2.44691898,\n",
       "       3.14006616, 3.14006616, 3.14006616, 3.14006616, 3.14006616,\n",
       "       3.14006616, 3.14006616, 3.14006616, 3.14006616, 2.73460106,\n",
       "       2.44691898, 3.14006616, 3.14006616, 3.14006616, 3.14006616,\n",
       "       3.14006616, 3.14006616, 3.14006616, 3.14006616, 3.14006616,\n",
       "       3.14006616, 2.73460106, 3.14006616, 3.14006616, 3.14006616,\n",
       "       3.14006616, 3.14006616, 3.14006616, 3.14006616, 3.14006616,\n",
       "       2.73460106, 3.14006616, 3.14006616, 3.14006616, 3.14006616,\n",
       "       2.73460106, 3.14006616, 3.14006616, 2.73460106, 3.14006616,\n",
       "       2.73460106, 3.14006616, 3.14006616, 3.14006616, 3.14006616,\n",
       "       3.14006616, 3.14006616, 3.14006616, 3.14006616, 3.14006616,\n",
       "       3.14006616, 3.14006616, 3.14006616, 2.22377543, 3.14006616,\n",
       "       2.73460106, 3.14006616, 3.14006616, 3.14006616, 3.14006616,\n",
       "       2.04145387, 3.14006616, 3.14006616, 2.73460106, 2.73460106,\n",
       "       3.14006616, 3.14006616, 3.14006616, 3.14006616, 3.14006616,\n",
       "       3.14006616, 3.14006616, 3.14006616, 3.14006616, 3.14006616,\n",
       "       3.14006616, 3.14006616, 3.14006616, 3.14006616, 3.14006616,\n",
       "       3.14006616, 3.14006616, 3.14006616, 3.14006616, 3.14006616,\n",
       "       2.73460106, 3.14006616, 1.7537718 , 3.14006616, 1.7537718 ,\n",
       "       3.14006616, 3.14006616, 2.44691898, 3.14006616, 3.14006616,\n",
       "       3.14006616, 3.14006616, 3.14006616, 3.14006616, 3.14006616,\n",
       "       2.73460106, 3.14006616, 3.14006616, 3.14006616, 3.14006616,\n",
       "       3.14006616, 3.14006616, 3.14006616, 3.14006616, 3.14006616,\n",
       "       3.14006616, 3.14006616, 3.14006616, 3.14006616, 3.14006616,\n",
       "       3.14006616, 3.14006616, 3.14006616, 3.14006616, 3.14006616,\n",
       "       3.14006616, 3.14006616, 3.14006616, 3.14006616, 2.73460106,\n",
       "       3.14006616, 3.14006616, 3.14006616, 3.14006616, 3.14006616,\n",
       "       3.14006616, 3.14006616, 3.14006616, 3.14006616, 3.14006616,\n",
       "       3.14006616, 3.14006616, 2.73460106, 3.14006616, 3.14006616,\n",
       "       3.14006616, 3.14006616, 3.14006616, 0.02655085, 3.14006616,\n",
       "       3.14006616, 3.14006616, 3.14006616, 3.14006616, 2.22377543,\n",
       "       3.14006616, 2.73460106, 3.14006616, 3.14006616, 3.14006616,\n",
       "       3.14006616, 3.14006616, 3.14006616, 3.14006616, 3.14006616,\n",
       "       3.14006616, 3.14006616, 3.14006616, 3.14006616, 3.14006616,\n",
       "       3.14006616, 3.14006616, 3.14006616, 3.14006616, 3.14006616,\n",
       "       2.73460106, 1.8873032 , 3.14006616, 3.14006616, 2.44691898,\n",
       "       3.14006616, 3.14006616, 3.14006616])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# IDF looks at the the number of documents where a word appears so we sum across the columns\n",
    "col_sums = np.sum(dtm, axis = 0)\n",
    "\n",
    "# IDF smooth formula (from Wikipedia page on tf-idf)\n",
    "idf_matrix = np.log(np.divide(len(poem_text), (1 + col_sums), where= col_sums != 0)) + 1\n",
    "idf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "011b8067",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.28546056, 0.        , 0.28546056, ..., 0.28546056, 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Element-wise multiplication of the tf_matrix and idf_matrix\n",
    "# Wikipedia page includes the tf-idf formula\n",
    "\n",
    "tf_idf_matrix = tf_matrix * idf_matrix\n",
    "tf_idf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "db68e9f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 16)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Redefine tf_idf_matrix as A\n",
    "\n",
    "A = tf_idf_matrix\n",
    "\n",
    "# SVD step 1: Compute eigenthings of ATA\n",
    "A_T = np.transpose(A)\n",
    "ATA = np.matmul(A_T, A)\n",
    "\n",
    "# Unpack the tuple from .eig\n",
    "ATA_eigenvalues, ATA_eigenvectors = np.linalg.eig(ATA)\n",
    "\n",
    "# SVD step 2: Compute eigenthings of AAT\n",
    "AAT = np.matmul(A, A_T)\n",
    "AAT_eigenvalues, AAT_eigenvectors = np.linalg.eig(AAT)\n",
    "\n",
    "# There is a theorem that tells us that the non-zero eigenvalues are the same between AAT and ATA\n",
    "# By inspection we can see that the first 16 eigenvalues of ATA are non-zero\n",
    "# We also know that the rank between ATA and AAT is the same since the # of non-zero eigenvalues is the same\n",
    "ATA_nonzero_eig = ATA_eigenvalues[:16]\n",
    "ATA_nonzero_eig\n",
    "\n",
    "AAT_nonzero_eig = AAT_eigenvalues[:16]\n",
    "\n",
    "assert ATA_nonzero_eig.all() == AAT_nonzero_eig.all() # We confirm that the non-zero eigenvalues are equal\n",
    "assert np.linalg.matrix_rank(AAT) == np.linalg.matrix_rank(ATA)\n",
    "\n",
    "# SVD step 3: Build U, V, ∑ from the matrix information\n",
    "\n",
    "sigma = np.sqrt(AAT_nonzero_eig) # Already asserted these are the same eigenvalues as ATA. Take sqrt since we have ∑^2 when we do ATA or AAT\n",
    "sigma_matrix = np.diag(sigma) # Use np.diag so we get a matrix for sigma instead of a 16 x 1 vector\n",
    "\n",
    "# Check orthogonality of eigenvectors in AAT\n",
    "U_orthocheck = np.dot(AAT_eigenvectors[0], AAT_eigenvectors[1]) # Answer: 1.3624863072118684e-15\n",
    "U = AAT_eigenvectors[:16]\n",
    "\n",
    "V_orthocheck = np.dot(ATA_eigenvectors[0], ATA_eigenvectors[1]) # Answer: 0.0064162921966990204-7.806255641895632e-18j\n",
    "V_orthocheck\n",
    "\n",
    "# Because V_orthocheck is not as close to zero as U_orthocheck check the eigenvalues of the first eigenvector to see how close they are\n",
    "# Conclusion: They are very close. Good to move on.\n",
    "AAT_eigenvalues[0] # Answer: 1.7298486774104262\n",
    "ATA_eigenvalues[0] # Answer: 1.7298486774104356+0j\n",
    "\n",
    "V = ATA_eigenvectors[:16]\n",
    "\n",
    "# Selects all rows and all columns except for the last one - the last column had all zeros so it was incorrect\n",
    "U_truncated = U[:, :-1] \n",
    "\n",
    "assert U_truncated.shape == (16, 16) # Confirm the shape is m x r (r = rank)\n",
    "assert sigma_matrix.shape == (16, 16) # Confirm the shape is r x r (r = rank). We should only have as many singular values as our rank.\n",
    "assert V.shape == (16, 188) # Confirm the shape is r x n (r = rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a2606e44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 188)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Construct a rank 16 approximation of A\n",
    "\n",
    "A_int = np.matmul(U_truncated, sigma_matrix)\n",
    "A = np.matmul(A_int, V)\n",
    "A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a775043b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
