{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6961744",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import sympy as sp\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c8223f",
   "metadata": {},
   "source": [
    "Steps in the smaller document-term example:\n",
    "\n",
    "1. Make the words and sentence lists\n",
    "2. Initialize the original document term matrix to be zero with the dimensions of our documents and words\n",
    "3. Loop through the documents and update the document term matrix with the counts of the words in the documents\n",
    "4. Apply the tf-idf methods and take the element-wise product of the tf matrix and the idf matrix\n",
    "5. Confirm that our tf-idf splitting is the same as the TfIdfVectorizer in sci-kit learn \n",
    "6. Now that we've confirmed our matrix, A, take the eigenthings of AAT and ATA, write down what these matrices mean\n",
    "7. Plot the singular vectors of U and V, plot the singular values ∑\n",
    "8. Interpret this and do the same thing again for another extreme example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "818cc437",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a dtm from three sentences and 5 words (should be 3x5)\n",
    "\n",
    "words = [\"elephant\", \"horse\", \"zebra\", \"donkey\", \"monkey\"]\n",
    "\n",
    "# Intention: Make one sentence random bunch of words, another that repeates, and another with some repeat of words \n",
    "documents = [\"elephant donkey zebra horse zebra monkey\",\n",
    "            \"elephant elephant elephant elephant elephant\",\n",
    "            \"horse horse horse monkey monkey horse\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "446759f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words = 'english')\n",
    "tf_idf_matrix = vectorizer.fit_transform(documents) # Learn vocab and perform idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8a3189d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic_1</th>\n",
       "      <th>topic_2</th>\n",
       "      <th>documents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.863239</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>elephant donkey zebra horse zebra monkey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.515884</td>\n",
       "      <td>0.801784</td>\n",
       "      <td>elephant elephant elephant elephant elephant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.692131</td>\n",
       "      <td>-0.597614</td>\n",
       "      <td>horse horse horse monkey monkey horse</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    topic_1   topic_2                                     documents\n",
       "0  0.863239  0.000000      elephant donkey zebra horse zebra monkey\n",
       "1  0.515884  0.801784  elephant elephant elephant elephant elephant\n",
       "2  0.692131 -0.597614         horse horse horse monkey monkey horse"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd = TruncatedSVD(n_components = 2) # This is our k value. For now I am using k = 2 so I can plot the data in 2D.\n",
    "lsa = svd.fit_transform(tf_idf_matrix) # Apply low-rank approximation to our tf_idf_matrix\n",
    "\n",
    "topic_encoded_tfidf_df = pd.DataFrame(lsa, columns = [\"topic_1\", \"topic_2\"])\n",
    "topic_encoded_tfidf_df['documents'] = documents\n",
    "topic_encoded_tfidf_df # We can see that most variance is happening in the first sentence for topic 1 but it doesn't explain much in topic 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e71debc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['donkey', 'elephant', 'horse', 'monkey', 'zebra'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary = vectorizer.get_feature_names_out()\n",
    "dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d31acb47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.23184364e-01,  5.15883963e-01,  5.85113263e-01,\n",
       "         3.77425362e-01,  4.46368729e-01],\n",
       "       [-1.15639006e-16,  8.01783726e-01, -5.34522484e-01,\n",
       "        -2.67261242e-01, -1.15237627e-16]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd.components_ # Only returns right singular vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91a230a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.22080427, 1.        ])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd.singular_values_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a140c7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic_1</th>\n",
       "      <th>topic_2</th>\n",
       "      <th>terms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.223184</td>\n",
       "      <td>-1.156390e-16</td>\n",
       "      <td>donkey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.515884</td>\n",
       "      <td>8.017837e-01</td>\n",
       "      <td>elephant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.585113</td>\n",
       "      <td>-5.345225e-01</td>\n",
       "      <td>horse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.377425</td>\n",
       "      <td>-2.672612e-01</td>\n",
       "      <td>monkey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.446369</td>\n",
       "      <td>-1.152376e-16</td>\n",
       "      <td>zebra</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    topic_1       topic_2     terms\n",
       "0  0.223184 -1.156390e-16    donkey\n",
       "1  0.515884  8.017837e-01  elephant\n",
       "2  0.585113 -5.345225e-01     horse\n",
       "3  0.377425 -2.672612e-01    monkey\n",
       "4  0.446369 -1.152376e-16     zebra"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "encoding_matrix = pd.DataFrame(svd.components_, index = ['topic_1', 'topic_2']).T\n",
    "encoding_matrix[\"terms\"] = dictionary\n",
    "display(encoding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1fd3d307",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top concepts? Dimensions in term-space explain most of variance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a51d94da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic_1</th>\n",
       "      <th>topic_2</th>\n",
       "      <th>terms</th>\n",
       "      <th>abs_topic_1</th>\n",
       "      <th>abs_topic_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.515884</td>\n",
       "      <td>8.017837e-01</td>\n",
       "      <td>elephant</td>\n",
       "      <td>0.515884</td>\n",
       "      <td>8.017837e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.585113</td>\n",
       "      <td>-5.345225e-01</td>\n",
       "      <td>horse</td>\n",
       "      <td>0.585113</td>\n",
       "      <td>5.345225e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.377425</td>\n",
       "      <td>-2.672612e-01</td>\n",
       "      <td>monkey</td>\n",
       "      <td>0.377425</td>\n",
       "      <td>2.672612e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.223184</td>\n",
       "      <td>-1.156390e-16</td>\n",
       "      <td>donkey</td>\n",
       "      <td>0.223184</td>\n",
       "      <td>1.156390e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.446369</td>\n",
       "      <td>-1.152376e-16</td>\n",
       "      <td>zebra</td>\n",
       "      <td>0.446369</td>\n",
       "      <td>1.152376e-16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    topic_1       topic_2     terms  abs_topic_1   abs_topic_2\n",
       "1  0.515884  8.017837e-01  elephant     0.515884  8.017837e-01\n",
       "2  0.585113 -5.345225e-01     horse     0.585113  5.345225e-01\n",
       "3  0.377425 -2.672612e-01    monkey     0.377425  2.672612e-01\n",
       "0  0.223184 -1.156390e-16    donkey     0.223184  1.156390e-16\n",
       "4  0.446369 -1.152376e-16     zebra     0.446369  1.152376e-16"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "encoding_matrix['abs_topic_1'] = np.abs(encoding_matrix['topic_1'])\n",
    "encoding_matrix['abs_topic_2'] = np.abs(encoding_matrix['topic_2'])\n",
    "display(encoding_matrix.sort_values('abs_topic_2', ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f193d66a",
   "metadata": {},
   "source": [
    "### New, maybe more informative example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd1957df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Finalizing applications filed by certain immig...</td>\n",
       "      <td>CNBC Article: Trump Admin Stops Green Card to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U.S. Citizenship and Immigration Services, the...</td>\n",
       "      <td>CNBC Article: Trump Admin Stops Green Card to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Trump's executive order, signed Jan. 20, title...</td>\n",
       "      <td>CNBC Article: Trump Admin Stops Green Card to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CBS News reported Tuesday that USCIS has direc...</td>\n",
       "      <td>CNBC Article: Trump Admin Stops Green Card to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The agency said in a statement attributed to a...</td>\n",
       "      <td>CNBC Article: Trump Admin Stops Green Card to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The statement did not address which applicatio...</td>\n",
       "      <td>CNBC Article: Trump Admin Stops Green Card to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Vetting on top of vetting</td>\n",
       "      <td>CNBC Article: Trump Admin Stops Green Card to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>For refugees and those who have been granted a...</td>\n",
       "      <td>CNBC Article: Trump Admin Stops Green Card to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>“There’s a certain amount of documentation you...</td>\n",
       "      <td>CNBC Article: Trump Admin Stops Green Card to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>People who are granted asylum or admitted to t...</td>\n",
       "      <td>CNBC Article: Trump Admin Stops Green Card to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Collins said it remains to be seen how the vet...</td>\n",
       "      <td>CNBC Article: Trump Admin Stops Green Card to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>“So if you didn’t have a middle name ... they ...</td>\n",
       "      <td>CNBC Article: Trump Admin Stops Green Card to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Trump took similar steps in his previous presi...</td>\n",
       "      <td>CNBC Article: Trump Admin Stops Green Card to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>\"In slowing down those applications, because U...</td>\n",
       "      <td>CNBC Article: Trump Admin Stops Green Card to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>The Migration Policy Institute reported in 202...</td>\n",
       "      <td>CNBC Article: Trump Admin Stops Green Card to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>From 2016 to 2020, spending on vetting nearly ...</td>\n",
       "      <td>CNBC Article: Trump Admin Stops Green Card to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>People are also vetted during the process of b...</td>\n",
       "      <td>CNBC Article: Trump Admin Stops Green Card to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>The pauses are being implemented just as USCIS...</td>\n",
       "      <td>CNBC Article: Trump Admin Stops Green Card to ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Sentence  \\\n",
       "0   Finalizing applications filed by certain immig...   \n",
       "1   U.S. Citizenship and Immigration Services, the...   \n",
       "2   Trump's executive order, signed Jan. 20, title...   \n",
       "3   CBS News reported Tuesday that USCIS has direc...   \n",
       "4   The agency said in a statement attributed to a...   \n",
       "5   The statement did not address which applicatio...   \n",
       "6                           Vetting on top of vetting   \n",
       "7   For refugees and those who have been granted a...   \n",
       "8   “There’s a certain amount of documentation you...   \n",
       "9   People who are granted asylum or admitted to t...   \n",
       "10  Collins said it remains to be seen how the vet...   \n",
       "11  “So if you didn’t have a middle name ... they ...   \n",
       "12  Trump took similar steps in his previous presi...   \n",
       "13  \"In slowing down those applications, because U...   \n",
       "14  The Migration Policy Institute reported in 202...   \n",
       "15  From 2016 to 2020, spending on vetting nearly ...   \n",
       "16  People are also vetted during the process of b...   \n",
       "17  The pauses are being implemented just as USCIS...   \n",
       "\n",
       "                                                Title  \n",
       "0   CNBC Article: Trump Admin Stops Green Card to ...  \n",
       "1   CNBC Article: Trump Admin Stops Green Card to ...  \n",
       "2   CNBC Article: Trump Admin Stops Green Card to ...  \n",
       "3   CNBC Article: Trump Admin Stops Green Card to ...  \n",
       "4   CNBC Article: Trump Admin Stops Green Card to ...  \n",
       "5   CNBC Article: Trump Admin Stops Green Card to ...  \n",
       "6   CNBC Article: Trump Admin Stops Green Card to ...  \n",
       "7   CNBC Article: Trump Admin Stops Green Card to ...  \n",
       "8   CNBC Article: Trump Admin Stops Green Card to ...  \n",
       "9   CNBC Article: Trump Admin Stops Green Card to ...  \n",
       "10  CNBC Article: Trump Admin Stops Green Card to ...  \n",
       "11  CNBC Article: Trump Admin Stops Green Card to ...  \n",
       "12  CNBC Article: Trump Admin Stops Green Card to ...  \n",
       "13  CNBC Article: Trump Admin Stops Green Card to ...  \n",
       "14  CNBC Article: Trump Admin Stops Green Card to ...  \n",
       "15  CNBC Article: Trump Admin Stops Green Card to ...  \n",
       "16  CNBC Article: Trump Admin Stops Green Card to ...  \n",
       "17  CNBC Article: Trump Admin Stops Green Card to ...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('trump1.txt', 'r') as f:\n",
    "    trump1 = f.readlines()\n",
    "    trump1 = [line.strip() for line in trump1] # Removes all \\n \n",
    "    trump1 = [s for s in trump1 if s.strip()] # Removes all empty strings\n",
    "\n",
    "sentences_df = pd.DataFrame(trump1, columns = ['Sentence'])\n",
    "sentences_df['Title'] = 'CNBC Article: Trump Admin Stops Green Card to do more vetting'\n",
    "sentences_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "12dad21f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Trump administration has paused the proces...</td>\n",
       "      <td>Guardian Article: Trump Officials Pause Greenc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CBS News reported that approved refugees are p...</td>\n",
       "      <td>Guardian Article: Trump Officials Pause Greenc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The move is likely to leave some immigrants gr...</td>\n",
       "      <td>Guardian Article: Trump Officials Pause Greenc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>“USCIS [United States Citizenship and Immigrat...</td>\n",
       "      <td>Guardian Article: Trump Officials Pause Greenc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adjustment of status is the process by which i...</td>\n",
       "      <td>Guardian Article: Trump Officials Pause Greenc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The DHS cited a presidential action issued by ...</td>\n",
       "      <td>Guardian Article: Trump Officials Pause Greenc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>It comes as a federal judge in Manhattan on Tu...</td>\n",
       "      <td>Guardian Article: Trump Officials Pause Greenc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Chung, 21, has lived in the US since she was s...</td>\n",
       "      <td>Guardian Article: Trump Officials Pause Greenc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Chung’s case has echoes of the ongoing detenti...</td>\n",
       "      <td>Guardian Article: Trump Officials Pause Greenc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>At least five students and academics of color ...</td>\n",
       "      <td>Guardian Article: Trump Officials Pause Greenc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>“What we’re seeing is the use of immigration l...</td>\n",
       "      <td>Guardian Article: Trump Officials Pause Greenc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Sentence  \\\n",
       "0   The Trump administration has paused the proces...   \n",
       "1   CBS News reported that approved refugees are p...   \n",
       "2   The move is likely to leave some immigrants gr...   \n",
       "3   “USCIS [United States Citizenship and Immigrat...   \n",
       "4   Adjustment of status is the process by which i...   \n",
       "5   The DHS cited a presidential action issued by ...   \n",
       "6   It comes as a federal judge in Manhattan on Tu...   \n",
       "7   Chung, 21, has lived in the US since she was s...   \n",
       "8   Chung’s case has echoes of the ongoing detenti...   \n",
       "9   At least five students and academics of color ...   \n",
       "10  “What we’re seeing is the use of immigration l...   \n",
       "\n",
       "                                                Title  \n",
       "0   Guardian Article: Trump Officials Pause Greenc...  \n",
       "1   Guardian Article: Trump Officials Pause Greenc...  \n",
       "2   Guardian Article: Trump Officials Pause Greenc...  \n",
       "3   Guardian Article: Trump Officials Pause Greenc...  \n",
       "4   Guardian Article: Trump Officials Pause Greenc...  \n",
       "5   Guardian Article: Trump Officials Pause Greenc...  \n",
       "6   Guardian Article: Trump Officials Pause Greenc...  \n",
       "7   Guardian Article: Trump Officials Pause Greenc...  \n",
       "8   Guardian Article: Trump Officials Pause Greenc...  \n",
       "9   Guardian Article: Trump Officials Pause Greenc...  \n",
       "10  Guardian Article: Trump Officials Pause Greenc...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open('trump2.txt', 'r') as f:\n",
    "    trump2 = f.readlines()\n",
    "    trump2 = [line.strip() for line in trump2 if line.strip()]\n",
    "\n",
    "trump2_df = pd.DataFrame(trump2, columns = ['Sentence'])\n",
    "assert len(trump2) == trump2_df.shape[0]\n",
    "\n",
    "trump2_df['Title'] = 'Guardian Article: Trump Officials Pause Greencard in Crackdown'\n",
    "display(trump2_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "49f3d483",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Finalizing applications filed by certain immig...</td>\n",
       "      <td>CNBC Article: Trump Admin Stops Green Card to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U.S. Citizenship and Immigration Services, the...</td>\n",
       "      <td>CNBC Article: Trump Admin Stops Green Card to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Trump's executive order, signed Jan. 20, title...</td>\n",
       "      <td>CNBC Article: Trump Admin Stops Green Card to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CBS News reported Tuesday that USCIS has direc...</td>\n",
       "      <td>CNBC Article: Trump Admin Stops Green Card to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The agency said in a statement attributed to a...</td>\n",
       "      <td>CNBC Article: Trump Admin Stops Green Card to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The statement did not address which applicatio...</td>\n",
       "      <td>CNBC Article: Trump Admin Stops Green Card to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Vetting on top of vetting</td>\n",
       "      <td>CNBC Article: Trump Admin Stops Green Card to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>For refugees and those who have been granted a...</td>\n",
       "      <td>CNBC Article: Trump Admin Stops Green Card to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>“There’s a certain amount of documentation you...</td>\n",
       "      <td>CNBC Article: Trump Admin Stops Green Card to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>People who are granted asylum or admitted to t...</td>\n",
       "      <td>CNBC Article: Trump Admin Stops Green Card to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Collins said it remains to be seen how the vet...</td>\n",
       "      <td>CNBC Article: Trump Admin Stops Green Card to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>“So if you didn’t have a middle name ... they ...</td>\n",
       "      <td>CNBC Article: Trump Admin Stops Green Card to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Trump took similar steps in his previous presi...</td>\n",
       "      <td>CNBC Article: Trump Admin Stops Green Card to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>\"In slowing down those applications, because U...</td>\n",
       "      <td>CNBC Article: Trump Admin Stops Green Card to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>The Migration Policy Institute reported in 202...</td>\n",
       "      <td>CNBC Article: Trump Admin Stops Green Card to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>From 2016 to 2020, spending on vetting nearly ...</td>\n",
       "      <td>CNBC Article: Trump Admin Stops Green Card to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>People are also vetted during the process of b...</td>\n",
       "      <td>CNBC Article: Trump Admin Stops Green Card to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>The pauses are being implemented just as USCIS...</td>\n",
       "      <td>CNBC Article: Trump Admin Stops Green Card to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>The Trump administration has paused the proces...</td>\n",
       "      <td>Guardian Article: Trump Officials Pause Greenc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>CBS News reported that approved refugees are p...</td>\n",
       "      <td>Guardian Article: Trump Officials Pause Greenc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>The move is likely to leave some immigrants gr...</td>\n",
       "      <td>Guardian Article: Trump Officials Pause Greenc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>“USCIS [United States Citizenship and Immigrat...</td>\n",
       "      <td>Guardian Article: Trump Officials Pause Greenc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Adjustment of status is the process by which i...</td>\n",
       "      <td>Guardian Article: Trump Officials Pause Greenc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>The DHS cited a presidential action issued by ...</td>\n",
       "      <td>Guardian Article: Trump Officials Pause Greenc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>It comes as a federal judge in Manhattan on Tu...</td>\n",
       "      <td>Guardian Article: Trump Officials Pause Greenc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Chung, 21, has lived in the US since she was s...</td>\n",
       "      <td>Guardian Article: Trump Officials Pause Greenc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Chung’s case has echoes of the ongoing detenti...</td>\n",
       "      <td>Guardian Article: Trump Officials Pause Greenc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>At least five students and academics of color ...</td>\n",
       "      <td>Guardian Article: Trump Officials Pause Greenc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>“What we’re seeing is the use of immigration l...</td>\n",
       "      <td>Guardian Article: Trump Officials Pause Greenc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Sentence  \\\n",
       "0   Finalizing applications filed by certain immig...   \n",
       "1   U.S. Citizenship and Immigration Services, the...   \n",
       "2   Trump's executive order, signed Jan. 20, title...   \n",
       "3   CBS News reported Tuesday that USCIS has direc...   \n",
       "4   The agency said in a statement attributed to a...   \n",
       "5   The statement did not address which applicatio...   \n",
       "6                           Vetting on top of vetting   \n",
       "7   For refugees and those who have been granted a...   \n",
       "8   “There’s a certain amount of documentation you...   \n",
       "9   People who are granted asylum or admitted to t...   \n",
       "10  Collins said it remains to be seen how the vet...   \n",
       "11  “So if you didn’t have a middle name ... they ...   \n",
       "12  Trump took similar steps in his previous presi...   \n",
       "13  \"In slowing down those applications, because U...   \n",
       "14  The Migration Policy Institute reported in 202...   \n",
       "15  From 2016 to 2020, spending on vetting nearly ...   \n",
       "16  People are also vetted during the process of b...   \n",
       "17  The pauses are being implemented just as USCIS...   \n",
       "18  The Trump administration has paused the proces...   \n",
       "19  CBS News reported that approved refugees are p...   \n",
       "20  The move is likely to leave some immigrants gr...   \n",
       "21  “USCIS [United States Citizenship and Immigrat...   \n",
       "22  Adjustment of status is the process by which i...   \n",
       "23  The DHS cited a presidential action issued by ...   \n",
       "24  It comes as a federal judge in Manhattan on Tu...   \n",
       "25  Chung, 21, has lived in the US since she was s...   \n",
       "26  Chung’s case has echoes of the ongoing detenti...   \n",
       "27  At least five students and academics of color ...   \n",
       "28  “What we’re seeing is the use of immigration l...   \n",
       "\n",
       "                                                Title  \n",
       "0   CNBC Article: Trump Admin Stops Green Card to ...  \n",
       "1   CNBC Article: Trump Admin Stops Green Card to ...  \n",
       "2   CNBC Article: Trump Admin Stops Green Card to ...  \n",
       "3   CNBC Article: Trump Admin Stops Green Card to ...  \n",
       "4   CNBC Article: Trump Admin Stops Green Card to ...  \n",
       "5   CNBC Article: Trump Admin Stops Green Card to ...  \n",
       "6   CNBC Article: Trump Admin Stops Green Card to ...  \n",
       "7   CNBC Article: Trump Admin Stops Green Card to ...  \n",
       "8   CNBC Article: Trump Admin Stops Green Card to ...  \n",
       "9   CNBC Article: Trump Admin Stops Green Card to ...  \n",
       "10  CNBC Article: Trump Admin Stops Green Card to ...  \n",
       "11  CNBC Article: Trump Admin Stops Green Card to ...  \n",
       "12  CNBC Article: Trump Admin Stops Green Card to ...  \n",
       "13  CNBC Article: Trump Admin Stops Green Card to ...  \n",
       "14  CNBC Article: Trump Admin Stops Green Card to ...  \n",
       "15  CNBC Article: Trump Admin Stops Green Card to ...  \n",
       "16  CNBC Article: Trump Admin Stops Green Card to ...  \n",
       "17  CNBC Article: Trump Admin Stops Green Card to ...  \n",
       "18  Guardian Article: Trump Officials Pause Greenc...  \n",
       "19  Guardian Article: Trump Officials Pause Greenc...  \n",
       "20  Guardian Article: Trump Officials Pause Greenc...  \n",
       "21  Guardian Article: Trump Officials Pause Greenc...  \n",
       "22  Guardian Article: Trump Officials Pause Greenc...  \n",
       "23  Guardian Article: Trump Officials Pause Greenc...  \n",
       "24  Guardian Article: Trump Officials Pause Greenc...  \n",
       "25  Guardian Article: Trump Officials Pause Greenc...  \n",
       "26  Guardian Article: Trump Officials Pause Greenc...  \n",
       "27  Guardian Article: Trump Officials Pause Greenc...  \n",
       "28  Guardian Article: Trump Officials Pause Greenc...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "concat_df = pd.concat([sentences_df, trump2_df], ignore_index=True) # Using ignore_index = True since I want one big dataframe\n",
    "display(concat_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7cca78e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>St. Patrick’s Day, celebrated annually on Marc...</td>\n",
       "      <td>Blog: St. Patrick's Day Ideas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Amidst the sea of green attire and shamrock-ad...</td>\n",
       "      <td>Blog: St. Patrick's Day Ideas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Let us uncover the top 20 St. Patrick’s Day ac...</td>\n",
       "      <td>Blog: St. Patrick's Day Ideas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Book a demo with us to learn how to try out th...</td>\n",
       "      <td>Blog: St. Patrick's Day Ideas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>But first, dust off your leprechaun hat, grab ...</td>\n",
       "      <td>Blog: St. Patrick's Day Ideas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1. Pot of Gold Scavenger Hunt</td>\n",
       "      <td>Blog: St. Patrick's Day Ideas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The “Pot of Gold Scavenger Hunt” is a fun St. ...</td>\n",
       "      <td>Blog: St. Patrick's Day Ideas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Here is a list of St. Patrick’s Day-themed ite...</td>\n",
       "      <td>Blog: St. Patrick's Day Ideas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Four-leaf clover – 10 points</td>\n",
       "      <td>Blog: St. Patrick's Day Ideas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Leprechaun hat – 15 points</td>\n",
       "      <td>Blog: St. Patrick's Day Ideas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Pot of gold (a small prop or image) – 20 points</td>\n",
       "      <td>Blog: St. Patrick's Day Ideas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Irish flag – 15 points</td>\n",
       "      <td>Blog: St. Patrick's Day Ideas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Lucky horseshoe – 20 points</td>\n",
       "      <td>Blog: St. Patrick's Day Ideas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Green feather boa – 15 points</td>\n",
       "      <td>Blog: St. Patrick's Day Ideas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Gold chocolate coins – 10 points</td>\n",
       "      <td>Blog: St. Patrick's Day Ideas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Players will have 30 minutes to search for the...</td>\n",
       "      <td>Blog: St. Patrick's Day Ideas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>After the St. Patrick’s Day scavenger hunt, te...</td>\n",
       "      <td>Blog: St. Patrick's Day Ideas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2. Shamrock Scavenger Hunt</td>\n",
       "      <td>Blog: St. Patrick's Day Ideas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>The “Shamrock Scavenger Hunt” is a fun St. Pat...</td>\n",
       "      <td>Blog: St. Patrick's Day Ideas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Before this St. Patrick’s Day event, paper sha...</td>\n",
       "      <td>Blog: St. Patrick's Day Ideas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Participants are then provided with clues to h...</td>\n",
       "      <td>Blog: St. Patrick's Day Ideas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Each shamrock found earns the team points, add...</td>\n",
       "      <td>Blog: St. Patrick's Day Ideas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>“Gold Coin Mystery” is an exciting team-buildi...</td>\n",
       "      <td>Blog: St. Patrick's Day Ideas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>In this competition, players sit in a circle w...</td>\n",
       "      <td>Blog: St. Patrick's Day Ideas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>The leprechaun then tries to guess which playe...</td>\n",
       "      <td>Blog: St. Patrick's Day Ideas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>As the leprechaun guesses, anticipation builds...</td>\n",
       "      <td>Blog: St. Patrick's Day Ideas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>This team-building game tests observation skil...</td>\n",
       "      <td>Blog: St. Patrick's Day Ideas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>4. Rainbow Coin Toss</td>\n",
       "      <td>Blog: St. Patrick's Day Ideas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>“Rainbow Coin Toss” is an energetic and entert...</td>\n",
       "      <td>Blog: St. Patrick's Day Ideas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>To set up, construct rainbow-colored tubes, ea...</td>\n",
       "      <td>Blog: St. Patrick's Day Ideas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Players take turns tossing coins into the tube...</td>\n",
       "      <td>Blog: St. Patrick's Day Ideas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>“Rainbow Coin Toss” promotes friendly competit...</td>\n",
       "      <td>Blog: St. Patrick's Day Ideas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>5. Leprechaun Hat Toss</td>\n",
       "      <td>Blog: St. Patrick's Day Ideas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>“Leprechaun Hat Toss” is a lively and festive ...</td>\n",
       "      <td>Blog: St. Patrick's Day Ideas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>As players engage in “Leprechaun Hat Toss,” th...</td>\n",
       "      <td>Blog: St. Patrick's Day Ideas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Friendly competition adds to the fun, creating...</td>\n",
       "      <td>Blog: St. Patrick's Day Ideas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>“Going Green Theme” is about transforming the ...</td>\n",
       "      <td>Blog: St. Patrick's Day Ideas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>This fun St. Patrick’s Day activity involves d...</td>\n",
       "      <td>Blog: St. Patrick's Day Ideas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>This activity creates a visually stimulating a...</td>\n",
       "      <td>Blog: St. Patrick's Day Ideas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>This St. Patrick’s Day team-building fosters a...</td>\n",
       "      <td>Blog: St. Patrick's Day Ideas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>7. Lucky Anon Letters</td>\n",
       "      <td>Blog: St. Patrick's Day Ideas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>“Lucky Anon Letters” is a heartwarming St. Pat...</td>\n",
       "      <td>Blog: St. Patrick's Day Ideas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>In this team-building activity, colleagues wri...</td>\n",
       "      <td>Blog: St. Patrick's Day Ideas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>By writing uplifting messages anonymously, tea...</td>\n",
       "      <td>Blog: St. Patrick's Day Ideas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>This St. Patrick’s Day activity enhances workp...</td>\n",
       "      <td>Blog: St. Patrick's Day Ideas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>8. Charmed Numbers</td>\n",
       "      <td>Blog: St. Patrick's Day Ideas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>“Charmed Numbers” is an exhilarating luck-base...</td>\n",
       "      <td>Blog: St. Patrick's Day Ideas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>In this fun game, participants draw numbers fr...</td>\n",
       "      <td>Blog: St. Patrick's Day Ideas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>The anticipation builds as each team member dr...</td>\n",
       "      <td>Blog: St. Patrick's Day Ideas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>This game promotes excitement, friendly compet...</td>\n",
       "      <td>Blog: St. Patrick's Day Ideas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>“Charmed Numbers” is a fun way to foster a fun...</td>\n",
       "      <td>Blog: St. Patrick's Day Ideas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>9. Lucky Leprechaun</td>\n",
       "      <td>Blog: St. Patrick's Day Ideas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>“Lucky Leprechaun” is a heartwarming game desi...</td>\n",
       "      <td>Blog: St. Patrick's Day Ideas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>In this game, participants take turns revealin...</td>\n",
       "      <td>Blog: St. Patrick's Day Ideas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>As players share their stories, they engage in...</td>\n",
       "      <td>Blog: St. Patrick's Day Ideas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>This St. Patrick’s Day activity fosters a sens...</td>\n",
       "      <td>Blog: St. Patrick's Day Ideas</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Sentence  \\\n",
       "0   St. Patrick’s Day, celebrated annually on Marc...   \n",
       "1   Amidst the sea of green attire and shamrock-ad...   \n",
       "2   Let us uncover the top 20 St. Patrick’s Day ac...   \n",
       "3   Book a demo with us to learn how to try out th...   \n",
       "4   But first, dust off your leprechaun hat, grab ...   \n",
       "5                       1. Pot of Gold Scavenger Hunt   \n",
       "6   The “Pot of Gold Scavenger Hunt” is a fun St. ...   \n",
       "7   Here is a list of St. Patrick’s Day-themed ite...   \n",
       "8                        Four-leaf clover – 10 points   \n",
       "9                          Leprechaun hat – 15 points   \n",
       "10    Pot of gold (a small prop or image) – 20 points   \n",
       "11                             Irish flag – 15 points   \n",
       "12                        Lucky horseshoe – 20 points   \n",
       "13                      Green feather boa – 15 points   \n",
       "14                   Gold chocolate coins – 10 points   \n",
       "15  Players will have 30 minutes to search for the...   \n",
       "16  After the St. Patrick’s Day scavenger hunt, te...   \n",
       "17                         2. Shamrock Scavenger Hunt   \n",
       "18  The “Shamrock Scavenger Hunt” is a fun St. Pat...   \n",
       "19  Before this St. Patrick’s Day event, paper sha...   \n",
       "20  Participants are then provided with clues to h...   \n",
       "21  Each shamrock found earns the team points, add...   \n",
       "22  “Gold Coin Mystery” is an exciting team-buildi...   \n",
       "23  In this competition, players sit in a circle w...   \n",
       "24  The leprechaun then tries to guess which playe...   \n",
       "25  As the leprechaun guesses, anticipation builds...   \n",
       "26  This team-building game tests observation skil...   \n",
       "27                               4. Rainbow Coin Toss   \n",
       "28  “Rainbow Coin Toss” is an energetic and entert...   \n",
       "29  To set up, construct rainbow-colored tubes, ea...   \n",
       "30  Players take turns tossing coins into the tube...   \n",
       "31  “Rainbow Coin Toss” promotes friendly competit...   \n",
       "32                             5. Leprechaun Hat Toss   \n",
       "33  “Leprechaun Hat Toss” is a lively and festive ...   \n",
       "34  As players engage in “Leprechaun Hat Toss,” th...   \n",
       "35  Friendly competition adds to the fun, creating...   \n",
       "36  “Going Green Theme” is about transforming the ...   \n",
       "37  This fun St. Patrick’s Day activity involves d...   \n",
       "38  This activity creates a visually stimulating a...   \n",
       "39  This St. Patrick’s Day team-building fosters a...   \n",
       "40                              7. Lucky Anon Letters   \n",
       "41  “Lucky Anon Letters” is a heartwarming St. Pat...   \n",
       "42  In this team-building activity, colleagues wri...   \n",
       "43  By writing uplifting messages anonymously, tea...   \n",
       "44  This St. Patrick’s Day activity enhances workp...   \n",
       "45                                 8. Charmed Numbers   \n",
       "46  “Charmed Numbers” is an exhilarating luck-base...   \n",
       "47  In this fun game, participants draw numbers fr...   \n",
       "48  The anticipation builds as each team member dr...   \n",
       "49  This game promotes excitement, friendly compet...   \n",
       "50  “Charmed Numbers” is a fun way to foster a fun...   \n",
       "51                                9. Lucky Leprechaun   \n",
       "52  “Lucky Leprechaun” is a heartwarming game desi...   \n",
       "53  In this game, participants take turns revealin...   \n",
       "54  As players share their stories, they engage in...   \n",
       "55  This St. Patrick’s Day activity fosters a sens...   \n",
       "\n",
       "                            Title  \n",
       "0   Blog: St. Patrick's Day Ideas  \n",
       "1   Blog: St. Patrick's Day Ideas  \n",
       "2   Blog: St. Patrick's Day Ideas  \n",
       "3   Blog: St. Patrick's Day Ideas  \n",
       "4   Blog: St. Patrick's Day Ideas  \n",
       "5   Blog: St. Patrick's Day Ideas  \n",
       "6   Blog: St. Patrick's Day Ideas  \n",
       "7   Blog: St. Patrick's Day Ideas  \n",
       "8   Blog: St. Patrick's Day Ideas  \n",
       "9   Blog: St. Patrick's Day Ideas  \n",
       "10  Blog: St. Patrick's Day Ideas  \n",
       "11  Blog: St. Patrick's Day Ideas  \n",
       "12  Blog: St. Patrick's Day Ideas  \n",
       "13  Blog: St. Patrick's Day Ideas  \n",
       "14  Blog: St. Patrick's Day Ideas  \n",
       "15  Blog: St. Patrick's Day Ideas  \n",
       "16  Blog: St. Patrick's Day Ideas  \n",
       "17  Blog: St. Patrick's Day Ideas  \n",
       "18  Blog: St. Patrick's Day Ideas  \n",
       "19  Blog: St. Patrick's Day Ideas  \n",
       "20  Blog: St. Patrick's Day Ideas  \n",
       "21  Blog: St. Patrick's Day Ideas  \n",
       "22  Blog: St. Patrick's Day Ideas  \n",
       "23  Blog: St. Patrick's Day Ideas  \n",
       "24  Blog: St. Patrick's Day Ideas  \n",
       "25  Blog: St. Patrick's Day Ideas  \n",
       "26  Blog: St. Patrick's Day Ideas  \n",
       "27  Blog: St. Patrick's Day Ideas  \n",
       "28  Blog: St. Patrick's Day Ideas  \n",
       "29  Blog: St. Patrick's Day Ideas  \n",
       "30  Blog: St. Patrick's Day Ideas  \n",
       "31  Blog: St. Patrick's Day Ideas  \n",
       "32  Blog: St. Patrick's Day Ideas  \n",
       "33  Blog: St. Patrick's Day Ideas  \n",
       "34  Blog: St. Patrick's Day Ideas  \n",
       "35  Blog: St. Patrick's Day Ideas  \n",
       "36  Blog: St. Patrick's Day Ideas  \n",
       "37  Blog: St. Patrick's Day Ideas  \n",
       "38  Blog: St. Patrick's Day Ideas  \n",
       "39  Blog: St. Patrick's Day Ideas  \n",
       "40  Blog: St. Patrick's Day Ideas  \n",
       "41  Blog: St. Patrick's Day Ideas  \n",
       "42  Blog: St. Patrick's Day Ideas  \n",
       "43  Blog: St. Patrick's Day Ideas  \n",
       "44  Blog: St. Patrick's Day Ideas  \n",
       "45  Blog: St. Patrick's Day Ideas  \n",
       "46  Blog: St. Patrick's Day Ideas  \n",
       "47  Blog: St. Patrick's Day Ideas  \n",
       "48  Blog: St. Patrick's Day Ideas  \n",
       "49  Blog: St. Patrick's Day Ideas  \n",
       "50  Blog: St. Patrick's Day Ideas  \n",
       "51  Blog: St. Patrick's Day Ideas  \n",
       "52  Blog: St. Patrick's Day Ideas  \n",
       "53  Blog: St. Patrick's Day Ideas  \n",
       "54  Blog: St. Patrick's Day Ideas  \n",
       "55  Blog: St. Patrick's Day Ideas  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open('stpatricks.txt', 'r') as f:\n",
    "    stpatricks = f.readlines()\n",
    "    stp_text = [line.strip() for line in stpatricks if line.strip()]\n",
    "    \n",
    "    \n",
    "stp_df = pd.DataFrame(stp_text, columns = ['Sentence'])\n",
    "stp_df['Title'] = 'Blog: St. Patrick\\'s Day Ideas'\n",
    "display(stp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "27677ccd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Finalizing applications filed by certain immig...</td>\n",
       "      <td>CNBC Article: Trump Admin Stops Green Card to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U.S. Citizenship and Immigration Services, the...</td>\n",
       "      <td>CNBC Article: Trump Admin Stops Green Card to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Trump's executive order, signed Jan. 20, title...</td>\n",
       "      <td>CNBC Article: Trump Admin Stops Green Card to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CBS News reported Tuesday that USCIS has direc...</td>\n",
       "      <td>CNBC Article: Trump Admin Stops Green Card to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The agency said in a statement attributed to a...</td>\n",
       "      <td>CNBC Article: Trump Admin Stops Green Card to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>9. Lucky Leprechaun</td>\n",
       "      <td>Blog: St. Patrick's Day Ideas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>“Lucky Leprechaun” is a heartwarming game desi...</td>\n",
       "      <td>Blog: St. Patrick's Day Ideas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>In this game, participants take turns revealin...</td>\n",
       "      <td>Blog: St. Patrick's Day Ideas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>As players share their stories, they engage in...</td>\n",
       "      <td>Blog: St. Patrick's Day Ideas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>This St. Patrick’s Day activity fosters a sens...</td>\n",
       "      <td>Blog: St. Patrick's Day Ideas</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>85 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Sentence  \\\n",
       "0   Finalizing applications filed by certain immig...   \n",
       "1   U.S. Citizenship and Immigration Services, the...   \n",
       "2   Trump's executive order, signed Jan. 20, title...   \n",
       "3   CBS News reported Tuesday that USCIS has direc...   \n",
       "4   The agency said in a statement attributed to a...   \n",
       "..                                                ...   \n",
       "80                                9. Lucky Leprechaun   \n",
       "81  “Lucky Leprechaun” is a heartwarming game desi...   \n",
       "82  In this game, participants take turns revealin...   \n",
       "83  As players share their stories, they engage in...   \n",
       "84  This St. Patrick’s Day activity fosters a sens...   \n",
       "\n",
       "                                                Title  \n",
       "0   CNBC Article: Trump Admin Stops Green Card to ...  \n",
       "1   CNBC Article: Trump Admin Stops Green Card to ...  \n",
       "2   CNBC Article: Trump Admin Stops Green Card to ...  \n",
       "3   CNBC Article: Trump Admin Stops Green Card to ...  \n",
       "4   CNBC Article: Trump Admin Stops Green Card to ...  \n",
       "..                                                ...  \n",
       "80                      Blog: St. Patrick's Day Ideas  \n",
       "81                      Blog: St. Patrick's Day Ideas  \n",
       "82                      Blog: St. Patrick's Day Ideas  \n",
       "83                      Blog: St. Patrick's Day Ideas  \n",
       "84                      Blog: St. Patrick's Day Ideas  \n",
       "\n",
       "[85 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Really simple concat\n",
    "\n",
    "sentence_df = pd.concat([concat_df, stp_df], ignore_index=True) # Using ignore_index = True since I want one big dataframe\n",
    "display(sentence_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bbd44843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the words\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "# Vectorize just the sentence, we don't care about vectorizing the Title\n",
    "bag_of_words = vectorizer.fit_transform(sentence_df.Sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9edad70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "svd = TruncatedSVD(n_components = 2)\n",
    "lsa = svd.fit_transform(bag_of_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "64a844c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic 1</th>\n",
       "      <th>Topic 2</th>\n",
       "      <th>sentence</th>\n",
       "      <th>Is_Trump</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.009682</td>\n",
       "      <td>0.001339</td>\n",
       "      <td>Finalizing applications filed by certain immig...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.023507</td>\n",
       "      <td>-0.004325</td>\n",
       "      <td>U.S. Citizenship and Immigration Services, the...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.018334</td>\n",
       "      <td>0.003281</td>\n",
       "      <td>Trump's executive order, signed Jan. 20, title...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.033366</td>\n",
       "      <td>-0.002017</td>\n",
       "      <td>CBS News reported Tuesday that USCIS has direc...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.010883</td>\n",
       "      <td>0.001513</td>\n",
       "      <td>The agency said in a statement attributed to a...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.189128</td>\n",
       "      <td>0.513166</td>\n",
       "      <td>9. Lucky Leprechaun</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.155096</td>\n",
       "      <td>0.213760</td>\n",
       "      <td>“Lucky Leprechaun” is a heartwarming game desi...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0.085555</td>\n",
       "      <td>0.124853</td>\n",
       "      <td>In this game, participants take turns revealin...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0.019370</td>\n",
       "      <td>0.046266</td>\n",
       "      <td>As players share their stories, they engage in...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0.369465</td>\n",
       "      <td>-0.179373</td>\n",
       "      <td>This St. Patrick’s Day activity fosters a sens...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>85 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Topic 1   Topic 2                                           sentence  \\\n",
       "0   0.009682  0.001339  Finalizing applications filed by certain immig...   \n",
       "1   0.023507 -0.004325  U.S. Citizenship and Immigration Services, the...   \n",
       "2   0.018334  0.003281  Trump's executive order, signed Jan. 20, title...   \n",
       "3   0.033366 -0.002017  CBS News reported Tuesday that USCIS has direc...   \n",
       "4   0.010883  0.001513  The agency said in a statement attributed to a...   \n",
       "..       ...       ...                                                ...   \n",
       "80  0.189128  0.513166                                9. Lucky Leprechaun   \n",
       "81  0.155096  0.213760  “Lucky Leprechaun” is a heartwarming game desi...   \n",
       "82  0.085555  0.124853  In this game, participants take turns revealin...   \n",
       "83  0.019370  0.046266  As players share their stories, they engage in...   \n",
       "84  0.369465 -0.179373  This St. Patrick’s Day activity fosters a sens...   \n",
       "\n",
       "    Is_Trump  \n",
       "0       True  \n",
       "1       True  \n",
       "2       True  \n",
       "3       True  \n",
       "4       True  \n",
       "..       ...  \n",
       "80     False  \n",
       "81     False  \n",
       "82     False  \n",
       "83     False  \n",
       "84     False  \n",
       "\n",
       "[85 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "topic_encoded_df = pd.DataFrame(lsa, columns = ['Topic 1', 'Topic 2'])\n",
    "topic_encoded_df['sentence'] = sentence_df.Sentence\n",
    "# Is there a way to combine this?\n",
    "topic_encoded_df['Is_Trump'] = (sentence_df.Title == \"Guardian Article: Trump Officials Pause Greencard in Crackdown\")\n",
    "topic_encoded_df['Is_Trump'] = (sentence_df.Title == \"CNBC Article: Trump Admin Stops Green Card to do more vetting\")\n",
    "display(topic_encoded_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3028fe98",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = topic_encoded_df.Is_Trump.sum()\n",
    "\n",
    "fal = len(topic_encoded_df) - ts\n",
    "fal\n",
    "\n",
    "# Ok - maybe try to see what happens when you add the norm argument to the tf-idf vectorizer?\n",
    "\n",
    "# And also see medium https://medium.com/analytics-vidhya/understand-tf-idf-by-building-it-from-scratch-adc11eba7142#:~:text=Term%20frequency%20adjusted%20for%20document,f(t%2Cd)) implentation\n",
    "\n",
    "#^ Confirm what happens actually happens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "26566ffa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['10', '11', '149', '15', '17th', '20', '2016', '2020', '2023',\n",
       "       '21', '30', '53', 'academics', 'accessories', 'accompanied',\n",
       "       'according', 'action', 'actions', 'activist', 'activities',\n",
       "       'activity', 'add', 'adding', 'additional', 'address', 'adds',\n",
       "       'adjusting', 'adjustment', 'administration', 'admission',\n",
       "       'admitted', 'adorned', 'adventure', 'affect', 'affected',\n",
       "       'agencies', 'agency', 'agenda', 'aggressively', 'aiming', 'aliens',\n",
       "       'alignment', 'amidst', 'ancestry', 'annually', 'anon', 'anonymous',\n",
       "       'anonymously', 'anticipation', 'appealing', 'applicants',\n",
       "       'application', 'applications', 'applied', 'apply', 'appreciation',\n",
       "       'appropriate', 'approved', 'area', 'arguing', 'arrange', 'asked',\n",
       "       'asking', 'assigned', 'asylee', 'asylum', 'atmosphere',\n",
       "       'attempting', 'attire', 'attorney', 'attributed', 'authorities',\n",
       "       'backlog', 'banners', 'based', 'benefits', 'billion', 'blank',\n",
       "       'blocked', 'bludgeon', 'boa', 'bonding', 'bonds', 'book', 'boost',\n",
       "       'bring', 'build', 'building', 'builds', 'bush', 'called',\n",
       "       'camaraderie', 'candies', 'capacity', 'card', 'cards', 'carried',\n",
       "       'carry', 'case', 'cbs', 'celebrate', 'celebrated', 'celebration',\n",
       "       'center', 'central', 'certain', 'chance', 'charmed', 'check',\n",
       "       'cheer', 'chocolate', 'chocolates', 'chung', 'circle', 'cited',\n",
       "       'citizenship', 'claiming', 'closely', 'closes', 'clover', 'clues',\n",
       "       'cohesive', 'coin', 'coins', 'collaborate', 'collaborative',\n",
       "       'colleague', 'colleagues', 'collins', 'color', 'colored',\n",
       "       'colorful', 'columbia', 'comb', 'come', 'comes', 'coming',\n",
       "       'communication', 'competition', 'complement', 'completion',\n",
       "       'comply', 'concerns', 'conduct', 'connection', 'connections',\n",
       "       'constitutional', 'construct', 'continues', 'contractors',\n",
       "       'coordination', 'corporate', 'correctly', 'country', 'coworkers',\n",
       "       'crackdown', 'creates', 'creating', 'criminal', 'cultural',\n",
       "       'customs', 'cut', 'day', 'decade', 'decipher', 'decorating',\n",
       "       'decors', 'decreased', 'deepen', 'degree', 'demo', 'department',\n",
       "       'deport', 'deportation', 'designated', 'designed', 'detaining',\n",
       "       'detention', 'develop', 'dhs', 'did', 'didn', 'different',\n",
       "       'directed', 'director', 'dislike', 'disqualify', 'disrupting',\n",
       "       'documentation', 'don', 'donald', 'draw', 'draws', 'drop', 'dust',\n",
       "       'earning', 'earns', 'echoes', 'economic', 'effort', 'element',\n",
       "       'embrace', 'empathy', 'employees', 'enacts', 'encounters',\n",
       "       'encouragement', 'encourages', 'encouraging', 'energetic',\n",
       "       'enforcement', 'engage', 'engages', 'engaging', 'enhances',\n",
       "       'enjoy', 'ensure', 'enter', 'entertaining', 'environment',\n",
       "       'escape', 'event', 'evidence', 'excitement', 'exciting',\n",
       "       'executive', 'exhilarating', 'experience', 'experiences',\n",
       "       'experts', 'eye', 'eyes', 'feather', 'federal', 'fee', 'festive',\n",
       "       'festivities', 'filed', 'filled', 'finalizing', 'fine', 'flag',\n",
       "       'foot', 'foreign', 'form', 'fortune', 'foster', 'fosters', 'fraud',\n",
       "       'freeze', 'friendly', 'fun', 'funded', 'game', 'gameplay', 'gaza',\n",
       "       'george', 'getting', 'goal', 'goes', 'going', 'gold', 'golden',\n",
       "       'good', 'government', 'grab', 'granted', 'green', 'growth',\n",
       "       'guardian', 'guess', 'guesses', 'guinness', 'hand', 'handles',\n",
       "       'happens', 'hardline', 'hat', 'head', 'headway', 'heartwarming',\n",
       "       'help', 'helps', 'hidden', 'hold', 'holder', 'holders', 'holding',\n",
       "       'holds', 'holiday', 'homeland', 'hoping', 'horseshoe', 'host',\n",
       "       'house', 'hunt', 'identified', 'identify', 'image', 'immersing',\n",
       "       'immersive', 'immigrants', 'immigration', 'implement',\n",
       "       'implemented', 'includes', 'increase', 'individuals', 'initiative',\n",
       "       'inside', 'instances', 'institute', 'intend', 'interaction',\n",
       "       'interactive', 'involves', 'ireland', 'irish', 'issued', 'items',\n",
       "       'jan', 'january', 'join', 'judge', 'just', 'khalil', 'know',\n",
       "       'known', 'laura', 'law', 'lawful', 'lawsuit', 'leaf', 'learn',\n",
       "       'leave', 'legal', 'leprechaun', 'let', 'letters', 'like', 'likely',\n",
       "       'limbo', 'limit', 'list', 'live', 'lived', 'lively', 'loads',\n",
       "       'locate', 'locations', 'long', 'longer', 'look', 'luck', 'lucky',\n",
       "       'mahmoud', 'maintain', 'making', 'manhattan', 'march', 'materials',\n",
       "       'maximum', 'means', 'media', 'member', 'members', 'messages',\n",
       "       'middle', 'migration', 'million', 'minimal', 'minutes', 'monday',\n",
       "       'money', 'morale', 'movement', 'mpi', 'mutual', 'mystery',\n",
       "       'national', 'nations', 'nbc', 'nearly', 'necessary', 'news',\n",
       "       'number', 'numbers', 'observation', 'observe', 'occurred',\n",
       "       'offers', 'office', 'officials', 'old', 'ongoing', 'operations',\n",
       "       'order', 'ordered', 'orders', 'overseas', 'paired', 'palestine',\n",
       "       'palestinian', 'paper', 'participants', 'participated',\n",
       "       'particularly', 'partners', 'path', 'patrick', 'patron', 'pause',\n",
       "       'paused', 'pauses', 'pending', 'people', 'perfect', 'permanent',\n",
       "       'personal', 'perspectives', 'petitions', 'pint', 'placing',\n",
       "       'player', 'players', 'plus', 'point', 'points', 'policy',\n",
       "       'political', 'portion', 'positivity', 'possible', 'pot',\n",
       "       'potential', 'predetermined', 'prepare', 'president',\n",
       "       'presidential', 'previous', 'prize', 'probably', 'problem',\n",
       "       'process', 'processing', 'promote', 'promotes', 'prompts', 'prop',\n",
       "       'protecting', 'protests', 'provide', 'provided', 'public',\n",
       "       'purpose', 'questions', 'quite', 'rainbow', 'rapid', 'read',\n",
       "       'records', 'reduced', 'reform', 'refuge', 'refugee', 'refugees',\n",
       "       'regions', 'related', 'relationships', 'remain', 'remains',\n",
       "       'report', 'reported', 'requires', 'resettlement', 'residency',\n",
       "       'resident', 'residents', 'revealing', 'revel', 'rights',\n",
       "       'rigorous', 'risks', 'room', 'safety', 'said', 'saint', 'samah',\n",
       "       'say', 'scavenger', 'score', 'screen', 'screened', 'screening',\n",
       "       'sea', 'seamlessly', 'search', 'secretly', 'security', 'seeing',\n",
       "       'seeking', 'seen', 'send', 'sense', 'serves', 'services',\n",
       "       'session', 'set', 'setup', 'seven', 'shades', 'shamrock',\n",
       "       'shamrocks', 'share', 'sharing', 'shortfall', 'shrink', 'signed',\n",
       "       'similar', 'single', 'sisay', 'sit', 'skills', 'slightly',\n",
       "       'slowing', 'small', 'smu', 'social', 'solidarity', 'solving',\n",
       "       'specific', 'speech', 'spending', 'spirit', 'spokesperson',\n",
       "       'spread', 'st', 'staff', 'start', 'statement', 'states', 'status',\n",
       "       'steps', 'stimulating', 'stories', 'storytelling', 'streamers',\n",
       "       'stronger', 'student', 'students', 'successful', 'support',\n",
       "       'supported', 'suppress', 'sure', 'surely', 'suspended', 'suspense',\n",
       "       'taking', 'tally', 'tank', 'tapestry', 'targeted', 'team',\n",
       "       'teammate', 'teams', 'teamwork', 'temporary', 'term', 'terrorists',\n",
       "       'tests', 'thematically', 'theme', 'themed', 'things', 'think',\n",
       "       'threats', 'thrill', 'time', 'titled', 'told', 'took', 'tooth',\n",
       "       'toss', 'tossing', 'traditions', 'transforming', 'treasures',\n",
       "       'treats', 'tries', 'tripled', 'trump', 'try', 'trying', 'tubes',\n",
       "       'tuesday', 'turns', 'ultimate', 'uncover', 'understanding',\n",
       "       'united', 'unity', 'universities', 'university',\n",
       "       'unpredictability', 'uplifting', 'uscis', 'use', 'using',\n",
       "       'usually', 'values', 'various', 'venerates', 'vet', 'vetted',\n",
       "       'vetting', 'vibrant', 'visa', 'visually', 'wait', 'wants', 'way',\n",
       "       'wear', 'website', 'week', 'white', 'win', 'winner', 'work',\n",
       "       'workload', 'workplace', 'worldwide', 'write', 'writing', 'year',\n",
       "       'years', 'yunseo'], dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dictionary = vectorizer.get_feature_names_out()\n",
    "display(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "567ca1a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.65509255e-02,  1.63831246e-03,  3.79986123e-04, ...,\n",
       "         1.25439472e-02,  2.64045903e-04,  4.59057151e-04],\n",
       "       [ 3.17171656e-02,  2.97997768e-03, -1.74434527e-04, ...,\n",
       "        -8.09814537e-04, -2.81317667e-04,  8.89482078e-05]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "014c5f94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.0130516 , 1.76176558])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd.singular_values_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5be9d96d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic_1</th>\n",
       "      <th>topic_2</th>\n",
       "      <th>terms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.026551</td>\n",
       "      <td>0.031717</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001638</td>\n",
       "      <td>0.002980</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000380</td>\n",
       "      <td>-0.000174</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.065181</td>\n",
       "      <td>0.180662</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.011966</td>\n",
       "      <td>-0.006636</td>\n",
       "      <td>17th</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>632</th>\n",
       "      <td>0.015577</td>\n",
       "      <td>-0.005143</td>\n",
       "      <td>write</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633</th>\n",
       "      <td>0.011419</td>\n",
       "      <td>-0.000008</td>\n",
       "      <td>writing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634</th>\n",
       "      <td>0.012544</td>\n",
       "      <td>-0.000810</td>\n",
       "      <td>year</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>0.000264</td>\n",
       "      <td>-0.000281</td>\n",
       "      <td>years</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>0.000459</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>yunseo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>637 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      topic_1   topic_2    terms\n",
       "0    0.026551  0.031717       10\n",
       "1    0.001638  0.002980       11\n",
       "2    0.000380 -0.000174      149\n",
       "3    0.065181  0.180662       15\n",
       "4    0.011966 -0.006636     17th\n",
       "..        ...       ...      ...\n",
       "632  0.015577 -0.005143    write\n",
       "633  0.011419 -0.000008  writing\n",
       "634  0.012544 -0.000810     year\n",
       "635  0.000264 -0.000281    years\n",
       "636  0.000459  0.000089   yunseo\n",
       "\n",
       "[637 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "encoding_matrix = pd.DataFrame(svd.components_, index = ['topic_1', 'topic_2']).T\n",
    "\n",
    "encoding_matrix[\"terms\"] = dictionary\n",
    "display(encoding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "dd30edf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic_1</th>\n",
       "      <th>topic_2</th>\n",
       "      <th>terms</th>\n",
       "      <th>abs_topic_1</th>\n",
       "      <th>abs_topic_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>0.326052</td>\n",
       "      <td>-0.166657</td>\n",
       "      <td>day</td>\n",
       "      <td>0.326052</td>\n",
       "      <td>0.166657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>0.318218</td>\n",
       "      <td>-0.161884</td>\n",
       "      <td>patrick</td>\n",
       "      <td>0.318218</td>\n",
       "      <td>0.161884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>0.317562</td>\n",
       "      <td>-0.160745</td>\n",
       "      <td>st</td>\n",
       "      <td>0.317562</td>\n",
       "      <td>0.160745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563</th>\n",
       "      <td>0.252651</td>\n",
       "      <td>-0.023463</td>\n",
       "      <td>team</td>\n",
       "      <td>0.252651</td>\n",
       "      <td>0.023463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.199928</td>\n",
       "      <td>-0.087508</td>\n",
       "      <td>activity</td>\n",
       "      <td>0.199928</td>\n",
       "      <td>0.087508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>0.189461</td>\n",
       "      <td>-0.106635</td>\n",
       "      <td>hunt</td>\n",
       "      <td>0.189461</td>\n",
       "      <td>0.106635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0.187932</td>\n",
       "      <td>-0.043372</td>\n",
       "      <td>building</td>\n",
       "      <td>0.187932</td>\n",
       "      <td>0.043372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>0.185718</td>\n",
       "      <td>-0.052744</td>\n",
       "      <td>fun</td>\n",
       "      <td>0.185718</td>\n",
       "      <td>0.052744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>0.173148</td>\n",
       "      <td>0.214797</td>\n",
       "      <td>points</td>\n",
       "      <td>0.173148</td>\n",
       "      <td>0.214797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>0.170761</td>\n",
       "      <td>-0.092588</td>\n",
       "      <td>scavenger</td>\n",
       "      <td>0.170761</td>\n",
       "      <td>0.092588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>0.146009</td>\n",
       "      <td>0.529509</td>\n",
       "      <td>leprechaun</td>\n",
       "      <td>0.146009</td>\n",
       "      <td>0.529509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0.131378</td>\n",
       "      <td>-0.052158</td>\n",
       "      <td>camaraderie</td>\n",
       "      <td>0.131378</td>\n",
       "      <td>0.052158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>0.123095</td>\n",
       "      <td>-0.058787</td>\n",
       "      <td>shamrock</td>\n",
       "      <td>0.123095</td>\n",
       "      <td>0.058787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>0.122345</td>\n",
       "      <td>0.206839</td>\n",
       "      <td>lucky</td>\n",
       "      <td>0.122345</td>\n",
       "      <td>0.206839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>0.121456</td>\n",
       "      <td>0.355875</td>\n",
       "      <td>toss</td>\n",
       "      <td>0.121456</td>\n",
       "      <td>0.355875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      topic_1   topic_2        terms  abs_topic_1  abs_topic_2\n",
       "162  0.326052 -0.166657          day     0.326052     0.166657\n",
       "409  0.318218 -0.161884      patrick     0.318218     0.161884\n",
       "536  0.317562 -0.160745           st     0.317562     0.160745\n",
       "563  0.252651 -0.023463         team     0.252651     0.023463\n",
       "20   0.199928 -0.087508     activity     0.199928     0.087508\n",
       "295  0.189461 -0.106635         hunt     0.189461     0.106635\n",
       "87   0.187932 -0.043372     building     0.187932     0.043372\n",
       "251  0.185718 -0.052744          fun     0.185718     0.052744\n",
       "427  0.173148  0.214797       points     0.173148     0.214797\n",
       "489  0.170761 -0.092588    scavenger     0.170761     0.092588\n",
       "336  0.146009  0.529509   leprechaun     0.146009     0.529509\n",
       "91   0.131378 -0.052158  camaraderie     0.131378     0.052158\n",
       "511  0.123095 -0.058787     shamrock     0.123095     0.058787\n",
       "354  0.122345  0.206839        lucky     0.122345     0.206839\n",
       "583  0.121456  0.355875         toss     0.121456     0.355875"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "encoding_matrix['abs_topic_1'] = np.abs(encoding_matrix['topic_1'])\n",
    "encoding_matrix['abs_topic_2'] = np.abs(encoding_matrix['topic_2'])\n",
    "display(encoding_matrix.sort_values('abs_topic_1', ascending=False).head(15))\n",
    "\n",
    "\n",
    "# Get the .iloc of words\n",
    "\n",
    "# One of the reasons both topics seem to do with the st patricks day vs. others is because of document length?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0c01c8ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic_1</th>\n",
       "      <th>topic_2</th>\n",
       "      <th>terms</th>\n",
       "      <th>abs_topic_1</th>\n",
       "      <th>abs_topic_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>0.146009</td>\n",
       "      <td>0.529509</td>\n",
       "      <td>leprechaun</td>\n",
       "      <td>0.146009</td>\n",
       "      <td>0.529509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>0.111853</td>\n",
       "      <td>0.416460</td>\n",
       "      <td>hat</td>\n",
       "      <td>0.111853</td>\n",
       "      <td>0.416460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>0.121456</td>\n",
       "      <td>0.355875</td>\n",
       "      <td>toss</td>\n",
       "      <td>0.121456</td>\n",
       "      <td>0.355875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>0.173148</td>\n",
       "      <td>0.214797</td>\n",
       "      <td>points</td>\n",
       "      <td>0.173148</td>\n",
       "      <td>0.214797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>0.122345</td>\n",
       "      <td>0.206839</td>\n",
       "      <td>lucky</td>\n",
       "      <td>0.122345</td>\n",
       "      <td>0.206839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.065181</td>\n",
       "      <td>0.180662</td>\n",
       "      <td>15</td>\n",
       "      <td>0.065181</td>\n",
       "      <td>0.180662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>0.326052</td>\n",
       "      <td>-0.166657</td>\n",
       "      <td>day</td>\n",
       "      <td>0.326052</td>\n",
       "      <td>0.166657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>0.318218</td>\n",
       "      <td>-0.161884</td>\n",
       "      <td>patrick</td>\n",
       "      <td>0.318218</td>\n",
       "      <td>0.161884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>0.317562</td>\n",
       "      <td>-0.160745</td>\n",
       "      <td>st</td>\n",
       "      <td>0.317562</td>\n",
       "      <td>0.160745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>0.093289</td>\n",
       "      <td>0.126896</td>\n",
       "      <td>coin</td>\n",
       "      <td>0.093289</td>\n",
       "      <td>0.126896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>0.189461</td>\n",
       "      <td>-0.106635</td>\n",
       "      <td>hunt</td>\n",
       "      <td>0.189461</td>\n",
       "      <td>0.106635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>0.062076</td>\n",
       "      <td>0.103485</td>\n",
       "      <td>rainbow</td>\n",
       "      <td>0.062076</td>\n",
       "      <td>0.103485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>0.052264</td>\n",
       "      <td>0.103014</td>\n",
       "      <td>participants</td>\n",
       "      <td>0.052264</td>\n",
       "      <td>0.103014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>0.109181</td>\n",
       "      <td>0.095641</td>\n",
       "      <td>game</td>\n",
       "      <td>0.109181</td>\n",
       "      <td>0.095641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>0.170761</td>\n",
       "      <td>-0.092588</td>\n",
       "      <td>scavenger</td>\n",
       "      <td>0.170761</td>\n",
       "      <td>0.092588</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      topic_1   topic_2         terms  abs_topic_1  abs_topic_2\n",
       "336  0.146009  0.529509    leprechaun     0.146009     0.529509\n",
       "277  0.111853  0.416460           hat     0.111853     0.416460\n",
       "583  0.121456  0.355875          toss     0.121456     0.355875\n",
       "427  0.173148  0.214797        points     0.173148     0.214797\n",
       "354  0.122345  0.206839         lucky     0.122345     0.206839\n",
       "3    0.065181  0.180662            15     0.065181     0.180662\n",
       "162  0.326052 -0.166657           day     0.326052     0.166657\n",
       "409  0.318218 -0.161884       patrick     0.318218     0.161884\n",
       "536  0.317562 -0.160745            st     0.317562     0.160745\n",
       "122  0.093289  0.126896          coin     0.093289     0.126896\n",
       "295  0.189461 -0.106635          hunt     0.189461     0.106635\n",
       "457  0.062076  0.103485       rainbow     0.062076     0.103485\n",
       "404  0.052264  0.103014  participants     0.052264     0.103014\n",
       "253  0.109181  0.095641          game     0.109181     0.095641\n",
       "489  0.170761 -0.092588     scavenger     0.170761     0.092588"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "encoding_matrix['abs_topic_1'] = np.abs(encoding_matrix['topic_1'])\n",
    "encoding_matrix['abs_topic_2'] = np.abs(encoding_matrix['topic_2'])\n",
    "display(encoding_matrix.sort_values('abs_topic_2', ascending=False).head(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff7b3ba",
   "metadata": {},
   "source": [
    "### Decide what to do about the bottom later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ab529026",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'elephant': 0, 'horse': 1, 'zebra': 2, 'donkey': 3, 'monkey': 4}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_lookup = { v : k for k, v in enumerate(words)}\n",
    "word_lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "564f1a1d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dtm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m document\u001b[38;5;241m.\u001b[39msplit():\n\u001b[1;32m      3\u001b[0m         word_idx \u001b[38;5;241m=\u001b[39m word_lookup[word]\n\u001b[0;32m----> 4\u001b[0m         dtm[d_idx][word_idx] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m      5\u001b[0m dtm\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dtm' is not defined"
     ]
    }
   ],
   "source": [
    "for d_idx, document in enumerate(documents):\n",
    "    for word in document.split():\n",
    "        word_idx = word_lookup[word]\n",
    "        dtm[d_idx][word_idx] += 1\n",
    "dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95cca84b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Divide the raw term frequencies by the total number of words in each document\n",
    "tf_matrix = dtm / dtm.sum(axis = 1, keepdims=True)\n",
    "tf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0171dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_sums = np.count_nonzero(dtm, axis = 0) # We want the number of documents a term appears in. E.g. elephant appears twice\n",
    "idf_matrix = np.log(np.divide(1 + len(documents), (1 + col_sums))) + 1\n",
    "idf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c23c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_matrix = tf_matrix * idf_matrix\n",
    "\n",
    "# Unsure\n",
    "norms = np.linalg.norm(tf_idf_matrix, axis = 1, keepdims=True)\n",
    "tf_idf_matrix = tf_idf_matrix / norms\n",
    "tf_idf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77de0cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Confirm that this is correct with the library implementation\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(norm='l2', use_idf=True, smooth_idf=True)\n",
    "result = tfidf.fit_transform(documents)\n",
    "tfidf_matrix = result.toarray()\n",
    "tfidf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1976196a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I can confirm that my implementation and TfidfVectorizer are the same in different orders\n",
    "# The vectorizer uses alphabetical order while mine is not in alphabetical order\n",
    "tfidf.vocabulary_ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b991b2d",
   "metadata": {},
   "source": [
    "### Pause and interpret tf_idf values. Check: Do they make sense?\n",
    "\n",
    "IDF: Used to penalize common words since words that appear often across many documents don't tell us much."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4238e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library implementation\n",
    "\n",
    "\n",
    "U, S, VT = np.linalg.svd(tf_idf_matrix)\n",
    "print(f\"Left Singular Vectors: {U}\")\n",
    "print(f\"Singular Values: {S}\")\n",
    "print(f\"Right Singular Vectors: {VT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00dba993",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_U = pd.DataFrame(U, index = [sentence for sentence in documents], \n",
    "                   columns = [f\"Concept {i+1}\" for i in range(U.shape[1])])\n",
    "df_U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984c40b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_V = pd.DataFrame(np.transpose(VT), columns = [f\"Latent Topic {i+1}\" for i in range(VT.shape[0])],\n",
    "                    index = [word for word in words])                    \n",
    "df_V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72297d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_V[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9ad8bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
